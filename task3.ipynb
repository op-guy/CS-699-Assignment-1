{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "from operator import attrgetter\n",
    "from functools import reduce\n",
    "import random\n",
    "\n",
    "GRAY_CONVERTER = np.array([0.2989, 0.5870, 0.1140])\n",
    "EPSILON = np.finfo(float).eps\n",
    "\n",
    "train_path = r'.\\Group_1\\train'\n",
    "test_path = r'.\\Group_1\\test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.where(x >= 0, x, 0)\n",
    "\n",
    "def leaky_relu(x, alpha=0.3):\n",
    "    return np.where(x >= 0, x, alpha * x)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.apply_along_axis(lambda a: 1 / (1 + np.exp(-a)), 0, x)\n",
    "\n",
    "\n",
    "def convert_to_gray(image):\n",
    "    return np.dot(image[..., :3], GRAY_CONVERTER)\n",
    "\n",
    "\n",
    "def pad_with(vector, pad_width, iaxis, kwargs):\n",
    "    pad_value = kwargs.get('padder', 0)\n",
    "    vector[:pad_width[0]] = pad_value\n",
    "    vector[-pad_width[1]:] = pad_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionLayer:\n",
    "    def __init__(self, H2=2, W2=2, D2=1, K=1):\n",
    "        self.H2 = H2\n",
    "        self.W2 = W2\n",
    "        self.D2 = D2\n",
    "        self.K = K\n",
    "        self.filters = np.random.normal(scale=(1.0 / np.sqrt(K)), size=(K, H2, W2, D2)) / (H2 * W2 * D2)\n",
    "        self.bias = np.zeros(shape=(K, ))\n",
    "\n",
    "    def iterate_regions(self, input):\n",
    "        '''\n",
    "\n",
    "        Generates overlapping (H2 x W2) size patches on the input images to perform the convolution operation with\n",
    "\n",
    "        '''\n",
    "\n",
    "        H1, W1, _ = input.shape\n",
    "\n",
    "        H2, W2, D2 = attrgetter('H2', 'W2', 'D2')(self)\n",
    "\n",
    "        for i in range(H1 - H2 + 1):\n",
    "            for j in range(W1 - W2 + 1):\n",
    "                section = input[i: i + H2, j: j + W2]\n",
    "                yield section, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "\n",
    "        Returns a 3-d numpy array which is output of the convolution operation performed on the \n",
    "        input image with the created filters\n",
    "\n",
    "        '''\n",
    "\n",
    "        H1, W1, _ = input.shape\n",
    "\n",
    "        self.last_input = input\n",
    "\n",
    "        H2, W2, D2, K, filters, bias = attrgetter(\n",
    "            'H2', 'W2', 'D2', 'K', 'filters', 'bias')(self)\n",
    "\n",
    "        feature_maps = np.zeros(((H1 - H2 + 1), (W1 - W2 + 1), K))\n",
    "\n",
    "        for section, i, j in self.iterate_regions(input):\n",
    "            feature_maps[i, j] += np.sum(section\n",
    "                                         * filters, axis=(1, 2, 3))\n",
    "\n",
    "        feature_maps += bias\n",
    "        self.last_output = feature_maps\n",
    "\n",
    "        return feature_maps\n",
    "\n",
    "    def backprop(self, d_L_d_out, eta):\n",
    "        '''\n",
    "        \n",
    "        Returns the gradient of the convolution layer for backpropagation\n",
    "\n",
    "        '''\n",
    "        d_L_d_out = np.where(self.last_output < 0, 0, d_L_d_out)\n",
    "        \n",
    "        H2, W2, D2, K, filters, bias = attrgetter(\n",
    "            'H2', 'W2', 'D2', 'K', 'filters', 'bias')(self)\n",
    "\n",
    "        d_L_d_filters = np.zeros(self.filters.shape)\n",
    "        d_L_d_input = np.zeros(self.last_input.shape)\n",
    "\n",
    "        \n",
    "        for section, i, j in self.iterate_regions(self.last_input):\n",
    "            for k in range(self.K):\n",
    "                d_L_d_filters[k] += d_L_d_out[i, j, k] * section\n",
    "\n",
    "        rev_filters = np.swapaxes(filters[:, ::-1, ::-1, :], 0, 3)\n",
    "\n",
    "        \n",
    "        npad = ((2, 2), (2, 2), (0, 0))\n",
    "        padded_gradient = np.pad(d_L_d_out, pad_width=npad, mode='constant', constant_values=0)\n",
    "\n",
    "        \n",
    "        for section, i, j in self.iterate_regions(padded_gradient):\n",
    "            d_L_d_input[i, j] += np.sum(section * rev_filters, axis=(1, 2, 3))\n",
    "\n",
    "        \n",
    "        self.filters -= eta * d_L_d_filters\n",
    "        self.bias -= eta * np.sum(d_L_d_out, axis=(0, 1))\n",
    "\n",
    "        return d_L_d_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoolingLayer:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "\n",
    "    def iterate_regions(self, image):\n",
    "        '''\n",
    "\n",
    "        Generates non-overlapping pool_sizexpool_size image regions to pool over.\n",
    "\n",
    "        '''\n",
    "        size = attrgetter('pool_size')(self)\n",
    "        h, w, _ = image.shape\n",
    "        new_h = h // size\n",
    "        new_w = w // size\n",
    "\n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                im_region = image[(i * size):(i * size + size),\n",
    "                                  (j * size):(j * size + size)]\n",
    "                yield im_region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "\n",
    "        Returns a 3d numpy array with dimensions (h / 2, w / 2, num_filters).\n",
    "        - input is a 3d numpy array with dimensions (h, w, num_filters)\n",
    "\n",
    "        '''\n",
    "        size = attrgetter('pool_size')(self)\n",
    "        self.last_input = input\n",
    "\n",
    "        h, w, num_filters = input.shape\n",
    "        output = np.zeros((h // size, w // size, num_filters))\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backprop(self, d_L_d_out):\n",
    "        '''\n",
    "\n",
    "        Returns the loss gradient for this layer's inputs.\n",
    "        - d_L_d_out is the loss gradient for this layer's outputs.\n",
    "\n",
    "        '''\n",
    "        size = attrgetter('pool_size')(self)\n",
    "        d_L_d_input = np.zeros(self.last_input.shape)\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "            h, w, f = im_region.shape\n",
    "            amax = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                    for f2 in range(f):\n",
    "                        # If this pixel was the max value, copy the gradient to it.\n",
    "                        if im_region[i2, j2, f2] == amax[f2]:\n",
    "                            d_L_d_input[i * size + i2, j * size +\n",
    "                                        j2, f2] = d_L_d_out[i, j, f2]\n",
    "\n",
    "        return d_L_d_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "    def __init__(self, n_classes, input_size):\n",
    "        self.weights = np.random.normal(scale=(1.0 / np.sqrt(n_classes)),size=(input_size, n_classes)) / input_size\n",
    "        self.biases = np.zeros(shape=(n_classes, ))\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "\n",
    "        Returns the probability values for the classes.\n",
    "        - input can be any array with any dimensions.\n",
    "        \n",
    "        '''\n",
    "        self.last_input_shape = input.shape\n",
    "\n",
    "        input = input.flatten()\n",
    "        self.last_input = input\n",
    "\n",
    "        input_len, nodes = self.weights.shape\n",
    "\n",
    "        totals = np.dot(input, self.weights) + self.biases\n",
    "        self.last_totals = totals\n",
    "\n",
    "        exp = np.exp(totals)\n",
    "        # exp = np.exp(totals - np.amax(totals))\n",
    "        return exp / np.sum(exp, axis=0)\n",
    "\n",
    "    def backprop(self, d_L_d_out, eta):\n",
    "        '''\n",
    "        \n",
    "        Returns the loss gradient for this layer's inputs.\n",
    "        - d_L_d_out is the loss gradient for this layer's outputs.\n",
    "        - eta is a float.\n",
    "        \n",
    "        '''\n",
    "\n",
    "        for i, gradient in enumerate(d_L_d_out):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "\n",
    "            t_exp = np.exp(self.last_totals - np.amax(self.last_totals))\n",
    "\n",
    "            S = np.sum(t_exp)\n",
    "\n",
    "            d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\n",
    "            d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\n",
    "\n",
    "            d_t_d_w = self.last_input\n",
    "            d_t_d_b = 1\n",
    "            d_t_d_inputs = self.weights\n",
    "\n",
    "            d_L_d_t = gradient * d_out_d_t\n",
    "\n",
    "            d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n",
    "            d_L_d_b = d_L_d_t * d_t_d_b\n",
    "            d_L_d_inputs = d_t_d_inputs @ d_L_d_t\n",
    "            \n",
    "\n",
    "            self.weights -= eta * d_L_d_w\n",
    "            self.biases -= eta * d_L_d_b\n",
    "\n",
    "            return d_L_d_inputs.reshape(self.last_input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(image, label):\n",
    "    out = relu(conv1_layer.forward(image))\n",
    "    out = relu(conv2_layer.forward(out))\n",
    "    out = pool_layer.forward(out)\n",
    "    out = softmax_layer.forward(out)\n",
    "\n",
    "    \n",
    "    loss = -np.log(out[label] + EPSILON)\n",
    "    acc = 1 if np.argmax(out) == label else 0\n",
    "    return out, loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(image, label, eta=0.005):\n",
    "    out, loss, acc = apply(image, label)\n",
    "    gradient = np.zeros(3)\n",
    "    gradient[label] = -1 / (out[label] + EPSILON)\n",
    "    gradient = softmax_layer.backprop(gradient, eta)\n",
    "    gradient = pool_layer.backprop(gradient)\n",
    "    gradient = conv2_layer.backprop(gradient, eta)\n",
    "    gradient = conv1_layer.backprop(gradient, eta)\n",
    "\n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for label, item in enumerate(['bird', 'deer', 'truck']):  \n",
    "    path = os.path.join(train_path, item)\n",
    "    images += map(lambda img: (matplotlib.image.imread(os.path.join(path, img)) / 255.0, label),os.listdir(path)[:100])\n",
    "\n",
    "random.shuffle(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "for label, item in enumerate(['bird', 'deer', 'truck']):  \n",
    "    path = os.path.join(test_path, item)\n",
    "    test_images += map(lambda img: (matplotlib.image.imread(os.path.join(path, img)) / 255.0, label),os.listdir(path)[:10])\n",
    "\n",
    "random.shuffle(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "conv1_layer = ConvolutionLayer(3, 3, 3, 32)\n",
    "conv2_layer = ConvolutionLayer(3, 3, 32, 64)\n",
    "pool_layer = PoolingLayer(2)\n",
    "# softmax_layer = SoftmaxLayer(3, 15 * 15 * 32)\n",
    "softmax_layer = SoftmaxLayer(3, 14 * 14 * 64)\n",
    "\n",
    "print('Training...')\n",
    "for epochs in range(10):\n",
    "    random.shuffle(images)\n",
    "    true_val, total_loss = 0, 0\n",
    "    for i, img in enumerate(images):\n",
    "        loss, acc = train(*img, 0.001)\n",
    "        true_val += acc\n",
    "        total_loss += loss\n",
    "        print('[Step %d]: Average Loss %.3f | Accuracy: %d%%' %\n",
    "            (i + 1, total_loss / (i + 1), true_val * 100 / (i + 1)))\n",
    "    losses.append(total_loss / 300.0)\n",
    "    accs.append(true_val / 3.0)\n",
    "print('End train...')\n",
    "\n",
    "print('Testing...')\n",
    "true_val, total_loss = 0, 0\n",
    "for i, img in enumerate(test_images):\n",
    "    out, loss, acc = apply(*img)\n",
    "    true_val += acc\n",
    "    total_loss += loss\n",
    "    print('[Step %d]: Average Loss %.3f | Accuracy: %d%%' %\n",
    "            (i + 1, total_loss / (i + 1), true_val * 100 / (i + 1)))\n",
    "print('End test...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = matplotlib.image.imread(os.path.join(train_path, 'bird', '0000.jpg'))\n",
    "out1 = relu(conv1_layer.forward(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Outputs for Layer 1\")\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 20), facecolor='white')\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(out1[:, :, i], cmap=plt.get_cmap('gray'))\n",
    "    ax.set_title('Output of filter:{}'.format(i + 1))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = relu(conv2_layer.forward(out1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Outputs for Layer 1\")\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 20), facecolor='white')\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(out2[:, :, i], cmap=plt.get_cmap('gray'))\n",
    "    ax.set_title('Output of filter:{}'.format(i + 1))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 8), facecolor='white')\n",
    "fig.suptitle('Training data')\n",
    "axs[0].plot(range(1, 11), losses)\n",
    "axs[0].set_title('Avg Loss vs Epochs')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Avg Loss')\n",
    "axs[1].plot(range(1, 11), accs)\n",
    "axs[1].set_title('Accuracy vs Epochs')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3afff13452cee94f1d88eb459e846ba508eb564adb6568e1841af2d1922e5d2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
