{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "from operator import attrgetter\n",
    "from functools import reduce\n",
    "\n",
    "GRAY_CONVERTER = np.array([0.2989, 0.5870, 0.1140])\n",
    "EPSILON = np.finfo(float).eps\n",
    "\n",
    "train_path = r'.\\Group_1\\train'\n",
    "test_path = r'.\\Group_1\\test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.where(x >= 0, x, 0)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.apply_along_axis(lambda a: 1 / (1 + np.exp(-a)), 0, x)\n",
    "\n",
    "\n",
    "def convert_to_gray(image):\n",
    "    return np.dot(image[..., :3], GRAY_CONVERTER)\n",
    "\n",
    "\n",
    "def pad_with(vector, pad_width, iaxis, kwargs):\n",
    "    pad_value = kwargs.get('padder', 0)\n",
    "    vector[:pad_width[0]] = pad_value\n",
    "    vector[-pad_width[1]:] = pad_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionLayer:\n",
    "    def __init__(self, H2=2, W2=2, D2=1, K=1):\n",
    "        self.H2 = H2\n",
    "        self.W2 = W2\n",
    "        self.D2 = D2\n",
    "        self.K = K\n",
    "        self.filters = np.random.normal(scale=0.3, size=(K, H2, W2, D2))\n",
    "        self.bias = np.random.normal(scale=0.3, size=(K))\n",
    "\n",
    "    def convolve(self, input):\n",
    "        H1, W1, _ = input.shape\n",
    "\n",
    "        H2, W2, D2 = attrgetter('H2', 'W2', 'D2')(self)\n",
    "\n",
    "        for i in range(H1 - H2 + 1):\n",
    "            for j in range(W1 - W2 + 1):\n",
    "                section = input[i: i + H2, j: j + W2]\n",
    "                yield section, i, j\n",
    "\n",
    "    def calculate(self, input):\n",
    "        H1, W1, _ = input.shape\n",
    "\n",
    "        self.last_input = input\n",
    "\n",
    "        H2, W2, D2, K, filters, bias = attrgetter(\n",
    "            'H2', 'W2', 'D2', 'K', 'filters', 'bias')(self)\n",
    "\n",
    "        feature_maps = np.zeros(((H1 - H2 + 1), (W1 - W2 + 1), K))\n",
    "\n",
    "        for section, i, j in self.convolve(input):\n",
    "            feature_maps[i, j] = bias\n",
    "\n",
    "            if D2 == 1:\n",
    "                feature_maps[i, j] += np.sum(section * filters, axis=(1, 2))\n",
    "                continue\n",
    "\n",
    "            for k in range(D2):\n",
    "                feature_maps[i, j] += np.sum(section[:, :, k]\n",
    "                                             * filters[:, :, :, k], axis=(1, 2))\n",
    "\n",
    "        return feature_maps\n",
    "\n",
    "    def backprop(self, d_L_d_out, eta):\n",
    "        \n",
    "        H2, W2, D2, K, filters, bias = attrgetter(\n",
    "            'H2', 'W2', 'D2', 'K', 'filters', 'bias')(self)\n",
    "\n",
    "\n",
    "        d_L_d_filters = np.zeros(self.filters.shape)\n",
    "        d_L_d_input = np.zeros(self.last_input.shape)\n",
    "\n",
    "        for section, i, j in self.convolve(self.last_input):\n",
    "            for f in range(self.K):\n",
    "                for k in range(self.D2):\n",
    "                    d_L_d_filters[f, :, :, k] += d_L_d_out[i, j, f] * section[:, :, k]\n",
    "                    d_L_d_input[i : i + H2, j : j + W2, k] += d_L_d_out[i, j, f] * filters[f, :, :, k]\n",
    "        self.filters -= eta * d_L_d_filters\n",
    "        self.bias -= eta * np.sum(d_L_d_out, axis=(0, 1))\n",
    "\n",
    "        return d_L_d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoolingLayer:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "\n",
    "    def pooling(self, input):\n",
    "        H, W, _ = input.shape\n",
    "\n",
    "        for i in range(H // self.pool_size):\n",
    "            for j in range(W // self.pool_size):\n",
    "                x, y = i * self.pool_size, j * self.pool_size\n",
    "                section = input[x: x + self.pool_size, y:y + self.pool_size]\n",
    "                yield section, i, j\n",
    "\n",
    "    def calculate(self, input):\n",
    "        H, W, K = input.shape\n",
    "        self.last_input = input\n",
    "        pooled_maps = np.zeros((H // self.pool_size, W // self.pool_size, K))\n",
    "\n",
    "        for section, i, j in self.pooling(input):\n",
    "            pooled_maps[i, j] = np.amax(section, axis=(0, 1))\n",
    "\n",
    "        return pooled_maps\n",
    "\n",
    "    def backprop(self, d_L_d_out):\n",
    "        \n",
    "        d_L_d_input = np.zeros(self.last_input.shape)\n",
    "\n",
    "        for section, i, j in self.pooling(self.last_input):\n",
    "            h, w, d = section.shape\n",
    "            amax = np.amax(section, axis=(0, 1))\n",
    "\n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                    for k2 in range(d):\n",
    "                        if section[i2, j2, k2] == amax[k2]:\n",
    "                            d_L_d_input[i * self.pool_size + i2, j * self.pool_size +  + j2, k2] = d_L_d_out[i, j, k2]\n",
    "            \n",
    "        \n",
    "        return d_L_d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "    def __init__(self, n_classes, input_size):\n",
    "        self.n_classes = n_classes\n",
    "        self.input_size = input_size\n",
    "        self.w = np.random.normal(scale=0.3, size=(input_size, n_classes))\n",
    "        self.b = np.random.normal(scale=0.3, size=(n_classes, ))\n",
    "\n",
    "    def calculate(self, input):\n",
    "        self.last_input_shape = input.shape\n",
    "\n",
    "        flattened_input = input.flatten()\n",
    "        self.last_input = flattened_input\n",
    "        input_size, n_classes = attrgetter('input_size', 'n_classes')(self)\n",
    "\n",
    "        output = np.dot(flattened_input, self.w) + self.b\n",
    "        output = output - np.amax(output)\n",
    "        self.last_outputs = output\n",
    "        return np.exp(output) / np.sum(np.exp(output), axis=0)\n",
    "\n",
    "    def backprop(self, d_L_d_out, eta):\n",
    "        for i, gradient in enumerate(d_L_d_out):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "            t_exp = np.exp(self.last_outputs)\n",
    "            S = np.sum(t_exp)\n",
    "\n",
    "            d_out_d_t = (-t_exp[i] * t_exp) / (S ** 2)\n",
    "            d_out_d_t[i] = (t_exp[i] * (S - t_exp[i])) / (S ** 2)\n",
    "\n",
    "            print(t_exp)\n",
    "            print(d_out_d_t)\n",
    "            \n",
    "            d_t_d_w = self.last_input\n",
    "            d_t_d_b = 1\n",
    "            d_t_d_input = self.w\n",
    "\n",
    "            d_L_d_t = gradient * d_out_d_t\n",
    "\n",
    "            d_L_d_b = d_L_d_t * d_t_d_b\n",
    "            d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n",
    "            d_L_d_input = d_t_d_input @ d_L_d_t\n",
    "\n",
    "            self.w -= eta * d_L_d_w\n",
    "            self.b -= eta * d_L_d_b\n",
    "\n",
    "            return d_L_d_input.reshape(self.last_input_shape)\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_layer = ConvolutionLayer(3, 3, 3, 32)\n",
    "conv2_layer = ConvolutionLayer(3, 3, 32, 64)\n",
    "pool_layer = PoolingLayer(2)\n",
    "# softmax_layer = SoftmaxLayer(3, 15 * 15 * 32)\n",
    "softmax_layer = SoftmaxLayer(3, 14 * 14 * 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = matplotlib.image.imread(os.path.join(train_path, 'bird', '0000.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(image, label):\n",
    "    out = relu(conv1_layer.calculate(image))\n",
    "    out = relu(conv2_layer.calculate(out))\n",
    "    out = pool_layer.calculate(out)\n",
    "    out = softmax_layer.calculate(out)\n",
    "\n",
    "    loss = -np.log(out[label] + EPSILON)\n",
    "    acc = 1 if np.argmax(out) == label else 0\n",
    "\n",
    "    return out, loss, acc\n",
    "\n",
    "\n",
    "def train(image, label, eta=0.005):\n",
    "    out, loss, acc = apply(image, label)\n",
    "\n",
    "    gradient = np.zeros(3)\n",
    "    gradient[label] = -1 / (out[label] + EPSILON)\n",
    "    print(gradient)\n",
    "    gradient = softmax_layer.backprop(gradient, eta)\n",
    "    # print(gradient)\n",
    "    # gradient = pool_layer.backprop(gradient)\n",
    "    # gradient = conv2_layer.backprop(gradient, eta)\n",
    "    # gradient = conv1_layer.backprop(gradient, eta)\n",
    "\n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for label, item in enumerate(['bird', 'deer', 'truck']):  \n",
    "    path = os.path.join(train_path, item)\n",
    "    images += map(lambda img: (matplotlib.image.imread(os.path.join(path, img)), label),os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_val, total_loss = 0, 0\n",
    "\n",
    "\n",
    "for i, (img, label) in enumerate(images):\n",
    "    loss, acc = train(img, label, 0.01)\n",
    "    true_val += acc\n",
    "    total_loss += loss\n",
    "    print('[Step %d]: Average Loss %.3f | Accuracy: %d%%' %\n",
    "            (i + 1, total_loss / (i + 1), true_val * 100 / (i + 1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "for label, item in enumerate(['bird', 'deer', 'truck']):  \n",
    "    path = os.path.join(test_path, item)\n",
    "    test_images += map(lambda img: (matplotlib.image.imread(os.path.join(path, img)), label),os.listdir(path))\n",
    "\n",
    "random.shuffle(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_val, total_loss = 0, 0\n",
    "\n",
    "\n",
    "for i, (img, label) in enumerate(test_images):\n",
    "    loss, acc = train(img, label, 0.01)\n",
    "    true_val += acc\n",
    "    total_loss += loss\n",
    "    print('[Step %d]: Average Loss %.3f | Accuracy: %d%%' %\n",
    "            (i + 1, total_loss / (i + 1), true_val * 100 / (i + 1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.50359963e+15  0.00000000e+00  0.00000000e+00]\n",
      "[0. 0. 1.]\n",
      "[ 0. -0. -0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36.04365338911715, 0)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(image, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3afff13452cee94f1d88eb459e846ba508eb564adb6568e1841af2d1922e5d2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
